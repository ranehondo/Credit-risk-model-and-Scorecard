{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501    1296599       5000         5000           4975.0   \n",
       "1           1  1077430    1314167       2500         2500           2500.0   \n",
       "2           2  1077175    1313524       2400         2400           2400.0   \n",
       "3           3  1076863    1277178      10000        10000          10000.0   \n",
       "4           4  1075358    1311748       3000         3000           3000.0   \n",
       "\n",
       "         term  int_rate  installment grade  ... total_bal_il il_util  \\\n",
       "0   36 months     10.65       162.87     B  ...          NaN     NaN   \n",
       "1   60 months     15.27        59.83     C  ...          NaN     NaN   \n",
       "2   36 months     15.96        84.33     C  ...          NaN     NaN   \n",
       "3   36 months     13.49       339.31     C  ...          NaN     NaN   \n",
       "4   60 months     12.69        67.79     B  ...          NaN     NaN   \n",
       "\n",
       "  open_rv_12m open_rv_24m  max_bal_bc all_util total_rev_hi_lim inq_fi  \\\n",
       "0         NaN         NaN         NaN      NaN              NaN    NaN   \n",
       "1         NaN         NaN         NaN      NaN              NaN    NaN   \n",
       "2         NaN         NaN         NaN      NaN              NaN    NaN   \n",
       "3         NaN         NaN         NaN      NaN              NaN    NaN   \n",
       "4         NaN         NaN         NaN      NaN              NaN    NaN   \n",
       "\n",
       "  total_cu_tl inq_last_12m  \n",
       "0         NaN          NaN  \n",
       "1         NaN          NaN  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "loan_data = pd.read_csv('Documents/loan_data_2007_2014/loan_data_2007_2014.csv')\n",
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with more than 80% null value+\n",
    "loan_data.dropna(thresh = loan_data.shape[0]*0.2, how = 'all', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all redundant and forward_looking columns\n",
    "loan_data.drop(columns = ['id','member_id','sub_grade','emp_title','url','desc','title','zip_code','next_pymnt_d','recoveries','collection_recovery_fee','total_rec_prncp','total_rec_late_fee'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Current                                                0.480878\n",
       "Fully Paid                                             0.396193\n",
       "Charged Off                                            0.091092\n",
       "Late (31-120 days)                                     0.014798\n",
       "In Grace Period                                        0.006747\n",
       "Does not meet the credit policy. Status:Fully Paid     0.004263\n",
       "Late (16-30 days)                                      0.002612\n",
       "Default                                                0.001784\n",
       "Does not meet the credit policy. Status:Charged Off    0.001632\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the unique values in loan status column\n",
    "loan_data['loan_status'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column based on the loan_status column that will be our target variable\n",
    "loan_data['good_bad'] = np.where(loan_data.loc[:, 'loan_status'].isin(['Charged off', 'Default','Late (31-120 days)','Does not meet the credit policy.status:Charged off']),0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'loan_status' column\n",
    "loan_data.drop(columns = ['loan_status'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 80/20 while keeping the distribution of bad loans in test set same as that in the pre-split dataset\n",
    "X = loan_data.drop('good_bad', axis = 1)\n",
    "y = loan_data['good_bad']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard copy the X datasets to avoid Pandas' SettingWithCopyWarning when we play around with this data later on.\n",
    "# this is currently an open issue between Pandas and Scikit_learn teams\n",
    "\n",
    "X_train, X_test = X_train.copy(), X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean up the emp_length column, assign 0 to NANs, and convert to numeric\n",
    "\n",
    "def emp_length_converter(df, column):\n",
    "    df[column] = df[column].str.replace('\\+ years', '')\n",
    "    df[column] = df[column].str.replace('< 1 year', str(0))\n",
    "    df[column] = df[column].str.replace(' years', '')\n",
    "    df[column] = df[column].str.replace(' year', '')\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "    df[column].fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format and create a new column as a difference between today and the respective date\n",
    "\n",
    "def Date_columns(df, column):\n",
    "    \n",
    "    #store current month\n",
    "    today_date = pd.to_datetime('2021-06-01')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-457991f39bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# convert to datetime format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%b-%y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'column' is not defined"
     ]
    }
   ],
   "source": [
    "# convert to datetime format\n",
    "\n",
    "df[column] = pd.to_datetime(df[column], format = \"%b-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'today_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2eaa074eed4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# calculate the difference in months and add to the new column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mths_since_earliest_cr_line'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoday_date\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'today_date' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate the difference in months and add to the new column\n",
    "\n",
    "df['mths_since_earliest_cr_line' + column] = round(pd.to_numeric((today_date - df[column]) / np.timedelta64(1, 'M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make any resulting -ve values to be equal to the max date\n",
    "\n",
    "df['mths_since_earliest_cr_line' + column] = df['mths_since_earliest_cr_line' + column].apply(lambda x: df['mths_since_earliest_cr_line' + column].max() if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the original date column\n",
    "\n",
    "df.drop(columns = [column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to remove 'months' string from the 'term' column and convert it to numeric\n",
    "\n",
    "def loan_term_converter(f=df, column):\n",
    "    df[column] = pd.to_numeric(df[column].str.replace(' months', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply these functions to X_train\n",
    "\n",
    "date_columns(X_train, 'earliest_cr_line')\n",
    "date_columns(X_train, 'issue_d')\n",
    "date_columns(X_train, 'last_pymnt_d')\n",
    "date_columns(X_train, 'last_credit_pull_d')\n",
    "date_columns(X_train, 'emp_length')\n",
    "date_columns(X_train, 'term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first divide training data into categorical and numerical subsets\n",
    "\n",
    "X_train_cat = X_train.select_dtypes(include = 'object').copy()\n",
    "X_train_num = X_train.select_dtypes(include = 'number').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty dictionary to store chi-squared test results\n",
    "\n",
    "chi2_check = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each column in the training set to calculate chi-statistic with the target variable\n",
    "\n",
    "for column in X_train_cat:\n",
    "    chi, p, dof, ex = chi2_contingency(pd.crosstab(y_train, X_train_cat[column]))\n",
    "    chi2_check.setdefault('Feature',[]).append(column)\n",
    "    chi2_check.setdefault('p-value',[]).append(round(p, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dictionary to a DF\n",
    "\n",
    "chi2_result = pd.DataFrame(data = chi2_check)\n",
    "chi2_result.sort_values(by = ['p-value'], ascending = True, ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since f_class_if does not accept missing values, we will do a very crude imputation of missing values\n",
    "\n",
    "X_train_num.fillna(X_train_num.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F Statistic and corresponding p values\n",
    "\n",
    "F_statistic, p_values = f_classif(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a DF\n",
    "\n",
    "ANOVA_F_table = pd.DataFrame(data = {'Numerical_Feature': X_train_num.columns.values,\n",
    "\t\t\t\t\t'F-Score': F_statistic, 'p values': p_values.round(decimals=10)})\n",
    "ANOVA_F_table.sort_values(by = ['F-Score'], ascending = False, ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the top 20 numerical features in a list\n",
    "\n",
    "top_num_features = ANOVA_F_table.iloc[:20,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pair-wise correlations between them\n",
    "\n",
    "corrmat = X_train_num[top_num_features].corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the names of columns to be dropped in a list\n",
    "\n",
    "drop_columns_list = ANOVA_F_table.iloc[20:, 0].to_list()\n",
    "drop_columns_list.extend(chi2_result.iloc[4:, 0].to_list())\n",
    "drop_columns_list.extend(['out_prncp_inv', 'total_pymnt_inv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop these columns\n",
    "\n",
    "def col_to_drop(df, columns_list):\n",
    "    df.drop(columns = columns_list, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to X_train\n",
    "\n",
    "col_to_drop(X_train, drop_columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding and Update Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dummy variables\n",
    "\n",
    "def dummy_creation(df, columns_list):\n",
    "    df_dummies = []\n",
    "    for col in columns_list:\n",
    "        df_dummies.append(pd.get_dummies(df[col], prefix = col, prefix_sep = ':'))\n",
    "    df_dummies = pd.concat(df_dummies, axis = 1)\n",
    "    df = pd.concat([df, df_dummies], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to our final four categorical variables\n",
    "\n",
    "X_train = dummy_creation(X_train, ['grade', 'home_ownership', 'verification_status', 'purpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the test data with all functions defined so far\n",
    "\n",
    "emp_length_converter(X_test, 'emp_length')\n",
    "date_columns(X_test, 'earliest_cr_line')\n",
    "date_columns(X_test, 'issue_d')\n",
    "date_columns(X_test, 'last_pymnt_d')\n",
    "date_columns(X_test, 'last_credit_pull_d')\n",
    "loan_term_converter(X_test, 'term')\n",
    "col_to_drop(X_test, drop_columns_list)\n",
    "X_test = dummy_creation(X_test, ['grade', 'home_ownership', 'verification_status', 'purpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex the dummied test set variables to make sure all the feature columns in the training set are also available in the test set\n",
    "\n",
    "X_test = X_test.reindex(labels=X_train.columns, axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WoE Binning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate WoE and IV of categorical features\n",
    "# The function takes 3 arguments: a dataframe (X_train_prepr), a string (column name), and a dataframe (y_train_prepr).\n",
    "\n",
    "def woe_discrete(df, cat_variabe_name, y_df):\n",
    "    df = pd.concat([df[cat_variabe_name], y_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate WoE & IV of continuous variables\n",
    "#This is same as the function we defined earlier for discrete variables\n",
    "#The only difference are the 2 commented lines of code in the function \n",
    "#that results in the df being sorted by continuous variable values\n",
    "\n",
    "def woe_ordered_continuous(df, continuous_variabe_name, y_df):\n",
    "    df = pd.concat([df[continuous_variabe_name], y_df], axis = 1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    #df = df.sort_values(['WoE'])\n",
    "    #df = df.reset_index(drop = True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the default style of the graphs to the seaborn style.\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot WoE value\n",
    "\n",
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
    "    y = df_WoE['WoE']\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n",
    "    plt.xlabel(df_WoE.columns[0])\n",
    "    plt.ylabel('Weight of Evidence')\n",
    "    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the reference categories, i.e. one category from each of the global features\n",
    "\n",
    "ref_categories = ['mths_since_last_credit_pull_d:>75', 'mths_since_issue_d:>122', 'mths_since_earliest_cr_line:>434', 'total_rev_hi_lim:>79,780', \n",
    "                  'total_rec_int:>7,260', 'total_pymnt:>25,000', 'out_prncp:>15,437', 'revol_util:>1.0', 'inq_last_6mths:>4', 'dti:>35.191', \n",
    "                  'annual_inc:>150K', 'int_rate:>20.281', 'term:60', 'purpose:major_purch__car__home_impr', 'verification_status:Not Verified', \n",
    "                  'home_ownership:MORTGAGE', 'grade:G']\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformer class to create new categorical dummy features\n",
    "\n",
    "class WoE_Binning(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, X): # no *args or *kargs\n",
    "        self.X = X\n",
    "    def fit(self, X, y = None):\n",
    "        return self #nothing else to do\n",
    "    def transform(self, X):\n",
    "        X_new = X.loc[:, 'grade:A': 'grade:G']\n",
    "        X_new['home_ownership:OWN'] = X.loc[:,'home_ownership:OWN']\n",
    "        X_new['home_ownership:MORTGAGE'] = X.loc[:,'home_ownership:MORTGAGE']\n",
    "        X_new['home_ownership:OTHER_NONE_RENT'] = sum([X['home_ownership:OTHER'], X['home_ownership:NONE'], X['home_ownership:RENT']])\n",
    "        X_new = pd.concat([X_new, X.loc[:, 'verification_status:Not Verified':'verification_status:Verified']], axis = 1)\n",
    "        X_new['purpose:debt_consolidation'] = X.loc[:,'purpose:debt_consolidation']\n",
    "        X_new['purpose:credit_card'] = X.loc[:,'purpose:credit_card']\n",
    "        X_new['purpose:major_purch__car__home_impr'] = sum([X['purpose:major_purchase'], X['purpose:car'], X['purpose:home_improvement']])\n",
    "        X_new['purpose:educ__ren_en__sm_b__mov'] = sum([X['purpose:educational'], X['purpose:renewable_energy'], X['purpose:small_business'], \n",
    "                                                        X['purpose:moving']])\n",
    "        X_new['purpose:vacation__house__wedding__med__oth'] = sum([X['purpose:vacation'], X['purpose:house'], X['purpose:wedding'], \n",
    "                                                                   X['purpose:medical'], X['purpose:other']])\n",
    "        X_new['term:36'] = np.where((X['term'] == 36), 1, 0)\n",
    "        X_new['term:60'] = np.where((X['term'] == 60), 1, 0)\n",
    "        X_new['int_rate:<7.071'] = np.where((X['int_rate'] <= 7.071), 1, 0)\n",
    "        X_new['int_rate:7.071-10.374'] = np.where((X['int_rate'] > 7.071) & (X['int_rate'] <= 10.374), 1, 0)\n",
    "        X_new['int_rate:10.374-13.676'] = np.where((X['int_rate'] > 10.374) & (X['int_rate'] <= 13.676), 1, 0)\n",
    "        X_new['int_rate:13.676-15.74'] = np.where((X['int_rate'] > 13.676) & (X['int_rate'] <= 15.74), 1, 0)\n",
    "        X_new['int_rate:15.74-20.281'] = np.where((X['int_rate'] > 15.74) & (X['int_rate'] <= 20.281), 1, 0)\n",
    "        X_new['int_rate:>20.281'] = np.where((X['int_rate'] > 20.281), 1, 0)\n",
    "        X_new['annual_inc:missing'] = np.where(X['annual_inc'].isnull(), 1, 0)\n",
    "        X_new['annual_inc:<28,555'] = np.where((X['annual_inc'] <= 28555), 1, 0)\n",
    "        X_new['annual_inc:28,555-37,440'] = np.where((X['annual_inc'] > 28555) & (X['annual_inc'] <= 37440), 1, 0)\n",
    "        X_new['annual_inc:37,440-61,137'] = np.where((X['annual_inc'] > 37440) & (X['annual_inc'] <= 61137), 1, 0)\n",
    "        X_new['annual_inc:61,137-81,872'] = np.where((X['annual_inc'] > 61137) & (X['annual_inc'] <= 81872), 1, 0)\n",
    "        X_new['annual_inc:81,872-102,606'] = np.where((X['annual_inc'] > 81872) & (X['annual_inc'] <= 102606), 1, 0)\n",
    "        X_new['annual_inc:102,606-120,379'] = np.where((X['annual_inc'] > 102606) & (X['annual_inc'] <= 120379), 1, 0)\n",
    "        X_new['annual_inc:120,379-150,000'] = np.where((X['annual_inc'] > 120379) & (X['annual_inc'] <= 150000), 1, 0)\n",
    "        X_new['annual_inc:>150K'] = np.where((X['annual_inc'] > 150000), 1, 0)\n",
    "        X_new['dti:<=1.6'] = np.where((X['dti'] <= 1.6), 1, 0)\n",
    "        X_new['dti:1.6-5.599'] = np.where((X['dti'] > 1.6) & (X['dti'] <= 5.599), 1, 0)\n",
    "        X_new['dti:5.599-10.397'] = np.where((X['dti'] > 5.599) & (X['dti'] <= 10.397), 1, 0)\n",
    "        X_new['dti:10.397-15.196'] = np.where((X['dti'] > 10.397) & (X['dti'] <= 15.196), 1, 0)\n",
    "        X_new['dti:15.196-19.195'] = np.where((X['dti'] > 15.196) & (X['dti'] <= 19.195), 1, 0)\n",
    "        X_new['dti:19.195-24.794'] = np.where((X['dti'] > 19.195) & (X['dti'] <= 24.794), 1, 0)\n",
    "        X_new['dti:24.794-35.191'] = np.where((X['dti'] > 24.794) & (X['dti'] <= 35.191), 1, 0)\n",
    "        X_new['dti:>35.191'] = np.where((X['dti'] > 35.191), 1, 0)\n",
    "        X_new['inq_last_6mths:missing'] = np.where(X['inq_last_6mths'].isnull(), 1, 0)\n",
    "        X_new['inq_last_6mths:0'] = np.where((X['inq_last_6mths'] == 0), 1, 0)\n",
    "        X_new['inq_last_6mths:1-2'] = np.where((X['inq_last_6mths'] >= 1) & (X['inq_last_6mths'] <= 2), 1, 0)\n",
    "        X_new['inq_last_6mths:3-4'] = np.where((X['inq_last_6mths'] >= 3) & (X['inq_last_6mths'] <= 4), 1, 0)\n",
    "        X_new['inq_last_6mths:>4'] = np.where((X['inq_last_6mths'] > 4), 1, 0)\n",
    "        X_new['revol_util:missing'] = np.where(X['revol_util'].isnull(), 1, 0)\n",
    "        X_new['revol_util:<0.1'] = np.where((X['revol_util'] <= 0.1), 1, 0)\n",
    "        X_new['revol_util:0.1-0.2'] = np.where((X['revol_util'] > 0.1) & (X['revol_util'] <= 0.2), 1, 0)\n",
    "        X_new['revol_util:0.2-0.3'] = np.where((X['revol_util'] > 0.2) & (X['revol_util'] <= 0.3), 1, 0)\n",
    "        X_new['revol_util:0.3-0.4'] = np.where((X['revol_util'] > 0.3) & (X['revol_util'] <= 0.4), 1, 0)\n",
    "        X_new['revol_util:0.4-0.5'] = np.where((X['revol_util'] > 0.4) & (X['revol_util'] <= 0.5), 1, 0)\n",
    "        X_new['revol_util:0.5-0.6'] = np.where((X['revol_util'] > 0.5) & (X['revol_util'] <= 0.6), 1, 0)\n",
    "        X_new['revol_util:0.6-0.7'] = np.where((X['revol_util'] > 0.6) & (X['revol_util'] <= 0.7), 1, 0)\n",
    "        X_new['revol_util:0.7-0.8'] = np.where((X['revol_util'] > 0.7) & (X['revol_util'] <= 0.8), 1, 0)\n",
    "        X_new['revol_util:0.8-0.9'] = np.where((X['revol_util'] > 0.8) & (X['revol_util'] <= 0.9), 1, 0)\n",
    "        X_new['revol_util:0.9-1.0'] = np.where((X['revol_util'] > 0.9) & (X['revol_util'] <= 1.0), 1, 0)\n",
    "        X_new['revol_util:>1.0'] = np.where((X['revol_util'] > 1.0), 1, 0)\n",
    "        X_new['out_prncp:<1,286'] = np.where((X['out_prncp'] <= 1286), 1, 0)\n",
    "        X_new['out_prncp:1,286-6,432'] = np.where((X['out_prncp'] > 1286) & (X['out_prncp'] <= 6432), 1, 0)\n",
    "        X_new['out_prncp:6,432-9,005'] = np.where((X['out_prncp'] > 6432) & (X['out_prncp'] <= 9005), 1, 0)\n",
    "        X_new['out_prncp:9,005-10,291'] = np.where((X['out_prncp'] > 9005) & (X['out_prncp'] <= 10291), 1, 0)\n",
    "        X_new['out_prncp:10,291-15,437'] = np.where((X['out_prncp'] > 10291) & (X['out_prncp'] <= 15437), 1, 0)\n",
    "        X_new['out_prncp:>15,437'] = np.where((X['out_prncp'] > 15437), 1, 0)\n",
    "        X_new['total_pymnt:<10,000'] = np.where((X['total_pymnt'] <= 10000), 1, 0)\n",
    "        X_new['total_pymnt:10,000-15,000'] = np.where((X['total_pymnt'] > 10000) & (X['total_pymnt'] <= 15000), 1, 0)\n",
    "        X_new['total_pymnt:15,000-20,000'] = np.where((X['total_pymnt'] > 15000) & (X['total_pymnt'] <= 20000), 1, 0)\n",
    "        X_new['total_pymnt:20,000-25,000'] = np.where((X['total_pymnt'] > 20000) & (X['total_pymnt'] <= 25000), 1, 0)\n",
    "        X_new['total_pymnt:>25,000'] = np.where((X['total_pymnt'] > 25000), 1, 0)\n",
    "        X_new['total_rec_int:<1,089'] = np.where((X['total_rec_int'] <= 1089), 1, 0)\n",
    "        X_new['total_rec_int:1,089-2,541'] = np.where((X['total_rec_int'] > 1089) & (X['total_rec_int'] <= 2541), 1, 0)\n",
    "        X_new['total_rec_int:2,541-4,719'] = np.where((X['total_rec_int'] > 2541) & (X['total_rec_int'] <= 4719), 1, 0)\n",
    "        X_new['total_rec_int:4,719-7,260'] = np.where((X['total_rec_int'] > 4719) & (X['total_rec_int'] <= 7260), 1, 0)\n",
    "        X_new['total_rec_int:>7,260'] = np.where((X['total_rec_int'] > 7260), 1, 0)\n",
    "        X_new['total_rev_hi_lim:missing'] = np.where(X['total_rev_hi_lim'].isnull(), 1, 0)\n",
    "        X_new['total_rev_hi_lim:<6,381'] = np.where((X['total_rev_hi_lim'] <= 6381), 1, 0)\n",
    "        X_new['total_rev_hi_lim:6,381-19,144'] = np.where((X['total_rev_hi_lim'] > 6381) & (X['total_rev_hi_lim'] <= 19144), 1, 0)\n",
    "        X_new['total_rev_hi_lim:19,144-25,525'] = np.where((X['total_rev_hi_lim'] > 19144) & (X['total_rev_hi_lim'] <= 25525), 1, 0)\n",
    "        X_new['total_rev_hi_lim:25,525-35,097'] = np.where((X['total_rev_hi_lim'] > 25525) & (X['total_rev_hi_lim'] <= 35097), 1, 0)\n",
    "        X_new['total_rev_hi_lim:35,097-54,241'] = np.where((X['total_rev_hi_lim'] > 35097) & (X['total_rev_hi_lim'] <= 54241), 1, 0)\n",
    "        X_new['total_rev_hi_lim:54,241-79,780'] = np.where((X['total_rev_hi_lim'] > 54241) & (X['total_rev_hi_lim'] <= 79780), 1, 0)\n",
    "        X_new['total_rev_hi_lim:>79,780'] = np.where((X['total_rev_hi_lim'] > 79780), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:missing'] = np.where(X['mths_since_earliest_cr_line'].isnull(), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:<125'] = np.where((X['mths_since_earliest_cr_line'] <= 125), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:125-167'] = np.where((X['mths_since_earliest_cr_line'] > 125) & (X['mths_since_earliest_cr_line'] <= 167), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:167-249'] = np.where((X['mths_since_earliest_cr_line'] > 167) & (X['mths_since_earliest_cr_line'] <= 249), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:249-331'] = np.where((X['mths_since_earliest_cr_line'] > 249) & (X['mths_since_earliest_cr_line'] <= 331), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:331-434'] = np.where((X['mths_since_earliest_cr_line'] > 331) & (X['mths_since_earliest_cr_line'] <= 434), 1, 0)\n",
    "        X_new['mths_since_earliest_cr_line:>434'] = np.where((X['mths_since_earliest_cr_line'] > 434), 1, 0)\n",
    "        X_new['mths_since_issue_d:<79'] = np.where((X['mths_since_issue_d'] <= 79), 1, 0)\n",
    "        X_new['mths_since_issue_d:79-89'] = np.where((X['mths_since_issue_d'] > 79) & (X['mths_since_issue_d'] <= 89), 1, 0)\n",
    "        X_new['mths_since_issue_d:89-100'] = np.where((X['mths_since_issue_d'] > 89) & (X['mths_since_issue_d'] <= 100), 1, 0)\n",
    "        X_new['mths_since_issue_d:100-122'] = np.where((X['mths_since_issue_d'] > 100) & (X['mths_since_issue_d'] <= 122), 1, 0)\n",
    "        X_new['mths_since_issue_d:>122'] = np.where((X['mths_since_issue_d'] > 122), 1, 0)\n",
    "        X_new['mths_since_last_credit_pull_d:missing'] = np.where(X['mths_since_last_credit_pull_d'].isnull(), 1, 0)\n",
    "        X_new['mths_since_last_credit_pull_d:<56'] = np.where((X['mths_since_last_credit_pull_d'] <= 56), 1, 0)\n",
    "        X_new['mths_since_last_credit_pull_d:56-61'] = np.where((X['mths_since_last_credit_pull_d'] > 56) & (X['mths_since_last_credit_pull_d'] <= 61), 1, 0)\n",
    "        X_new['mths_since_last_credit_pull_d:61-75'] = np.where((X['mths_since_last_credit_pull_d'] > 61) & (X['mths_since_last_credit_pull_d'] <= 75), 1, 0)\n",
    "        X_new['mths_since_last_credit_pull_d:>75'] = np.where((X['mths_since_last_credit_pull_d'] > 75), 1, 0)\n",
    "        X_new.drop(columns = ref_categories, inplace = True)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define modeling pipeline\n",
    "\n",
    "reg = LogisticRegression(max_iter=1000, class_weight = 'balanced')\n",
    "woe_transform = WoE_Binning(X)\n",
    "pipeline = Pipeline(steps=[('woe', woe_transform), ('model', reg)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-validation criteria\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\n",
    "\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring = 'roc_auc', cv = cv)\n",
    "AUROC = np.mean(scores)\n",
    "GINI = AUROC * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean AUROC score and Gini\n",
    "\n",
    "print('Mean AUROC: %.4f' % (AUROC))\n",
    "print('Gini: %.4f' % (GINI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the pipeline on the whole training set\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary table\n",
    "# first create a transformed training set through our WoE_Binning custom class\n",
    "\n",
    "X_train_woe_transformed = woe_transform.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the column names in X_train as a list\n",
    "\n",
    "feature_name = X_train_woe_transformed.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of our logistic regression model\n",
    "\n",
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the dataframe, called 'Coefficients'\n",
    "\n",
    "summary_table['Coefficients'] = np.transpose(pipeline['model'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the index of every row of the dataframe with 1 to store our model intercept in 1st row\n",
    "\n",
    "summary_table.index = summary_table.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign our model intercept to this new row\n",
    "\n",
    "summary_table.loc[0] = ['Intercept', pipeline['model'].intercept_[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by index\n",
    "\n",
    "summary_table.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for predictions and model evaluation on the test set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preditions on our test set\n",
    "\n",
    "y_hat_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted probabilities\n",
    "\n",
    "y_hat_test_proba = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the probabilities of only the positive class (class 1 - default) \n",
    "\n",
    "y_hat_test_proba = y_hat_test_proba[:][: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create a new DF with actual classes and the predicted probabilities\n",
    "# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\n",
    "\n",
    "y_test_temp = y_test.copy()\n",
    "y_test_temp.reset_index(drop = True, inplace = True)\n",
    "y_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "\n",
    "y_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the index of one dataframe equal to the index of another dataframe.\n",
    "\n",
    "y_test_proba.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values required to plot a ROC curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n",
    "                                 y_test_proba['y_hat_test_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n",
    "\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\n",
    "\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\n",
    "\n",
    "AUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Gini from AUROC\n",
    "\n",
    "Gini = AUROC * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print AUROC and Gini\n",
    "\n",
    "print('AUROC: %.4f' % (AUROC))\n",
    "print('Gini: %.4f' % (Gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a PR curve\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "\n",
    "no_skill = len(y_test[y_test == 1]) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the no skill precision-recall curve\n",
    "\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values required to plot a PR curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], \n",
    "                                                       y_test_proba['y_hat_test_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "\n",
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('PR curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scorecard Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code related to scorecard development is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with one column with values from the 'reference_categories' list\n",
    "\n",
    "df_ref_categories = pd.DataFrame(ref_categories, columns = ['Feature name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a second column, called 'Coefficients', which contains only 0 values.\n",
    "\n",
    "df_ref_categories['Coefficients'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates two dataframes\n",
    "\n",
    "df_scorecard = pd.concat([summary_table, df_ref_categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "\n",
    "df_scorecard.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column, called 'Original feature name', which contains the value of the 'Feature name' column\n",
    "\n",
    "df_scorecard['Original feature name'] = df_scorecard['Feature name'].str.split(':').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the min and max threshholds for our scorecard\n",
    "\n",
    "min_score = 300\n",
    "max_score = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the minimum coefficients of each category within the original feature name\n",
    "\n",
    "min_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].min().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the maximum coefficients of each category within the original feature name\n",
    "\n",
    "max_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].max().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column that has the imputed calculated Score based scaled from the coefficients\n",
    "\n",
    "df_scorecard['Score - Calculation'] = df_scorecard['Coefficients'] * (max_score - min_score) / (\n",
    "\tmax_sum_coef - min_sum_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the calculated score of the Intercept\n",
    "\n",
    "df_scorecard.loc[0, 'Score - Calculation'] = (\n",
    "\t(df_scorecard.loc[0,'Coefficients'] - min_sum_coef) /\n",
    "\t(max_sum_coef - min_sum_coef\n",
    "\t)) * (max_score - min_score) + min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the values of the 'Score - Calculation' column and store them in a new column\n",
    "\n",
    "df_scorecard['Score - Preliminary'] = df_scorecard['Score - Calculation'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the min and max possible scores of our scorecard\n",
    "\n",
    "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].min().sum()\n",
    "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].max().sum()\n",
    "print(min_sum_score_prel)\n",
    "print(max_sum_score_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so both our min and max scores are out by +1. we need to manually adjust this\n",
    "# Which one? We'll evaluate based on the rounding differences of the minimum category within each Original Feature Name.\n",
    "\n",
    "pd.options.display.max_rows = 102\n",
    "df_scorecard['Difference'] = df_scorecard['Score - Preliminary'] - df_scorecard['Score - Calculation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look like we can get by deducting 1 from the Intercept\n",
    "\n",
    "df_scorecard['Score - Final'] = df_scorecard['Score - Preliminary']\n",
    "df_scorecard.loc[0, 'Score - Final'] = 598\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck min and max possible scores\n",
    "\n",
    "print(df_scorecard.groupby('Original feature name')['Score - Final'].min().sum())\n",
    "print(df_scorecard.groupby('Original feature name')['Score - Final'].max().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate credit scores for test set\n",
    "# first create a transformed test set through our WoE_Binning custom class\n",
    "\n",
    "X_test_woe_transformed = woe_transform.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert an Intercept column in its beginning to align with the # of rows in scorecard\n",
    "\n",
    "X_test_woe_transformed.insert(0, 'Intercept', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of our final scorecard scores\n",
    "\n",
    "scorecard_scores = df_scorecard['Score - Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shapes of test set and scorecard before doing matrix dot multiplication\n",
    "\n",
    "print(X_test_woe_transformed.shape)\n",
    "print(scorecard_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the test set has 17 less columns than the rows in scorecard due to the reference categories\n",
    "# since the reference categories will always be scored as 0 based on the scorecard,\n",
    "# it is safe to add these categories to the end of test set with 0 values\n",
    "\n",
    "X_test_woe_transformed = pd.concat([X_test_woe_transformed, \n",
    "\t\t\t\t    pd.DataFrame(dict.fromkeys(ref_categories, [0]\n",
    "\t\t\t\t\t\t\t       * len(X_test_woe_transformed)), \n",
    "\t\t\t\t\t\t index = X_test_woe_transformed.index)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reshape scorecard_scores so that it is (102,1) to allow for matrix dot multiplication\n",
    "\n",
    "scorecard_scores = scorecard_scores.values.reshape(102, 1)\n",
    "print(X_test_woe_transformed.shape)\n",
    "print(scorecard_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix dot multiplication of test set with scorecard scores\n",
    "\n",
    "y_scores = X_test_woe_transformed.dot(scorecard_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score cutoff for loan approvals\n",
    "# Calculate Youden's J-Statistic to identify the best threshhold\n",
    "\n",
    "J = tpr - fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the index of the largest J\n",
    "\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold: %f' % (best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DF comprising of the thresholds from the ROC output\n",
    "\n",
    "df_cutoffs = pd.DataFrame(thresholds, columns = ['thresholds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcue Score corresponding to each threshold\n",
    "\n",
    "df_cutoffs['Score'] = ((np.log(df_cutoffs['thresholds'] / (1 - df_cutoffs['thresholds'])) - min_sum_coef) * \n",
    "                       ((max_score - min_score) / (max_sum_coef - min_sum_coef)) + min_score).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function called 'n_approved' which assigns a value of 1 if a predicted probability\n",
    "is greater than the parameter p, which is a threshold, and a value of 0, if it is not.\n",
    "Then it sums the column.\n",
    "Thus, for given any percentage values, the function will return\n",
    "the number of rows wih estimated probabilites greater than the threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_approved(p):\n",
    "    return np.where(y_test_proba['y_hat_test_proba'] >= p, 1, 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that all credit applications above a given probability of being 'good' will be approved,\n",
    "# when we apply the 'n_approved' function to a threshold, it will return the number of approved applications.\n",
    "# Thus, here we calculate the number of approved appliations for al thresholds.\n",
    "\n",
    "df_cutoffs['N Approved'] = df_cutoffs['thresholds'].apply(n_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we calculate the number of rejected applications for each threshold.\n",
    "# It is the difference between the total number of applications and the approved applications for that threshold.\n",
    "\n",
    "df_cutoffs['N Rejected'] = y_test_proba['y_hat_test_proba'].shape[0] - df_cutoffs['N Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approval rate equalts the ratio of the approved applications and all applications.\n",
    "\n",
    "df_cutoffs['Approval Rate'] = df_cutoffs['N Approved'] / y_test_proba['y_hat_test_proba'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection rate equals one minus approval rate.\n",
    "\n",
    "df_cutoffs['Rejection Rate'] = 1 - df_cutoffs['Approval Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the approval and rejection rates at our ideal threshold\n",
    "\n",
    "df_cutoffs[df_cutoffs['thresholds'].between(0.18657, 0.18658)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
